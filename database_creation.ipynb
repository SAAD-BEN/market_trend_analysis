{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Job Title', 'Location', 'Job Type', 'Experience level',\n",
       "       'Salary', 'Requirment of the company ', 'Facilities', 'country',\n",
       "       'Salary_in_1000_USD', 'Negociable', 'Asterisk', 'Job_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('data/preprocessed_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x28a2b38fbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = 'SQL Server'\n",
    "server = 'LAPTOP-K8C2EPLP\\SQLEXPRESS'\n",
    "database = 'data_science_jobs'\n",
    "\n",
    "\n",
    "connection_string = f\"\"\"\n",
    "                            DRIVER={driver};\n",
    "                            SERVER={server};\n",
    "                            DATABASE={database};\n",
    "                            Trusted_Connection=yes;\n",
    "\"\"\"\n",
    "connection = pyodbc.connect(connection_string)\n",
    "cursor = connection.cursor()\n",
    "cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the tables were already created\n",
    "tables = cursor.tables(tableType='TABLE', schema='dbo').fetchall()\n",
    "tables_names = [table.table_name for table in tables if table.table_schem == 'dbo']\n",
    "tables_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the .sql file\n",
    "if not tables_names :\n",
    "    cursor.execute(open('sql_server_db/creation.sql').read()[3:])\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company',\n",
       " 'Country',\n",
       " 'Facilities',\n",
       " 'Facilities_of_the_job',\n",
       " 'Job_posts',\n",
       " 'Job_Titles',\n",
       " 'Job_Titles_of_the_job',\n",
       " 'Location',\n",
       " 'Requirment_of_the_job',\n",
       " 'Requirments']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = cursor.tables(tableType='TABLE', schema='dbo').fetchall()\n",
    "tables_names = [table.table_name for table in tables if table.table_schem == 'dbo']\n",
    "tables_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for Company:\n",
      "Id\n",
      "Name\n",
      "\n",
      "\n",
      "Columns for Country:\n",
      "Country_code\n",
      "Country_name\n",
      "\n",
      "\n",
      "Columns for Facilities:\n",
      "Id\n",
      "Name\n",
      "\n",
      "\n",
      "Columns for Facilities_of_the_job:\n",
      "Job_id\n",
      "Facilitie_id\n",
      "\n",
      "\n",
      "Columns for Job_posts:\n",
      "Id\n",
      "Company_id\n",
      "Location_id\n",
      "Job_Type\n",
      "Experience_level\n",
      "Salary_in_1000_USD\n",
      "Negotiable\n",
      "Asterisk\n",
      "Job_category\n",
      "\n",
      "\n",
      "Columns for Job_Titles:\n",
      "Id\n",
      "Name\n",
      "\n",
      "\n",
      "Columns for Job_Titles_of_the_job:\n",
      "Job_id\n",
      "Job_Post_id\n",
      "\n",
      "\n",
      "Columns for Location:\n",
      "Id\n",
      "Full_location\n",
      "Country_code\n",
      "\n",
      "\n",
      "Columns for Requirment_of_the_job:\n",
      "Job_id\n",
      "Requirment_of_the_company_id\n",
      "\n",
      "\n",
      "Columns for Requirments:\n",
      "Id\n",
      "Name\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check columns for each table\n",
    "for table_name in tables_names:\n",
    "    columns = cursor.columns(table=table_name, schema='dbo').fetchall()\n",
    "    print(f'Columns for {table_name}:')\n",
    "    for column in columns:\n",
    "        print(column.column_name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incerting to the data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data into a table\n",
    "def insert_data(table_name, data):\n",
    "    columns = cursor.columns(table=table_name, schema='dbo').fetchall()\n",
    "    columns_names = [column.column_name for column in columns]\n",
    "    columns_names = ', '.join(columns_names)\n",
    "    values = ', '.join(['?' for _ in range(len(columns_names.split(', ')))])\n",
    "    query = f\"INSERT INTO {table_name} ({columns_names}) VALUES ({values})\"\n",
    "    cursor.executemany(query, data)\n",
    "    connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# company -> facilities -> requierements -> country -> location -> job_posts -> facilities_of_job -> requierements of job -> Job_Titles -> Job_Titles_Of_Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill company table\n",
    "companies_df = pd.DataFrame({'Company': df['Company'].unique()})\n",
    "# generate an id for each company \n",
    "companies_df['Company_id'] = companies_df['Company'].astype('category').cat.codes\n",
    "companies_df = companies_df[['Company_id', 'Company']]\n",
    "# as a list of tuples\n",
    "companies = list(companies_df.itertuples(index=False, name=None))\n",
    "# insert data into the table\n",
    "insert_data('Company', companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '15Five'),\n",
       " (1, '23andMe'),\n",
       " (2, '24-7 Intouch'),\n",
       " (3, '2K'),\n",
       " (4, '2U'),\n",
       " (5, '360dialog GmbH'),\n",
       " (6, '3Cloud'),\n",
       " (7, '3Pillar Global'),\n",
       " (8, '605'),\n",
       " (9, '66degrees')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM Company').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facilities\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '401(k) matching'),\n",
       " (2, 'Career development'),\n",
       " (3, 'Cell phone stipend'),\n",
       " (4, 'Competitive pay'),\n",
       " (5, 'Conferences'),\n",
       " (6, 'Contract'),\n",
       " (7, 'Equity'),\n",
       " (8, 'Fertility benefits'),\n",
       " (9, 'Fitness / gym'),\n",
       " (10, 'Flat hierarchy')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group Requirment of the company in 1 list then get the unique values\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: x.split(','))\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# get the unique values of the list\n",
    "facilities = list(set([j for i in df['Facilities'].values for j in i]))\n",
    "# generate an id for each facility\n",
    "facilities_df = pd.DataFrame({'Facility': facilities})\n",
    "facilities_df['Facility_id'] = facilities_df['Facility'].astype('category').cat.codes\n",
    "facilities_df = facilities_df[['Facility_id', 'Facility']]\n",
    "facilities_df = facilities_df[1:]\n",
    "facilities_df = [tuple(row) for row in facilities_df.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Facilities', facilities_df)\n",
    "cursor.execute('SELECT * FROM Facilities').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requierements\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '.NET'),\n",
       " (2, '3D Reconstruction'),\n",
       " (3, '3D graphics'),\n",
       " (4, 'A/B testing'),\n",
       " (5, 'AGI'),\n",
       " (6, 'AI art'),\n",
       " (7, 'AI content'),\n",
       " (8, 'AI governance'),\n",
       " (9, 'AI strategy'),\n",
       " (10, 'AIStats')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group Requirment of the company in 1 list then get the unique values\n",
    "df['Requirment of the company '] = df['Requirment of the company '].apply(lambda x: x.split(','))\n",
    "df['Requirment of the company '] = df['Requirment of the company '].apply(lambda x: list(set(x)))\n",
    "\n",
    "# get the unique values of the list\n",
    "job_requirements = list(set([j for i in df['Requirment of the company '].values for j in i]))\n",
    "# generate an id for each job requirement\n",
    "job_requirements_df = pd.DataFrame({'Job_requirement': job_requirements})\n",
    "job_requirements_df['Job_requirement_id'] = job_requirements_df['Job_requirement'].astype('category').cat.codes\n",
    "job_requirements_df = job_requirements_df[['Job_requirement_id', 'Job_requirement']]\n",
    "job_requirements_df = job_requirements_df[1:]\n",
    "job_requirements_df = [tuple(row) for row in job_requirements_df.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Requirments', job_requirements_df)\n",
    "cursor.execute('SELECT * FROM Requirments').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AD', 'Andorra'),\n",
       " ('AE', 'United Arab Emirates'),\n",
       " ('AF', 'Afghanistan'),\n",
       " ('AG', 'Antigua and Barbuda'),\n",
       " ('AI', 'Anguilla'),\n",
       " ('AL', 'Albania'),\n",
       " ('AM', 'Armenia'),\n",
       " ('AO', 'Angola'),\n",
       " ('AR', 'Argentina'),\n",
       " ('AS', 'American Samoa')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique values of countries\n",
    "countries = pd.DataFrame({'country': df['country'].unique()})\n",
    "# get country codes using geopy if its not 'Remote' or 'remote'\n",
    "countries_names = [country.name for country in pycountry.countries]\n",
    "countries_names.append('Remote')\n",
    "countries_codes = [country.alpha_2 for country in pycountry.countries]\n",
    "countries_codes.append('Remote')\n",
    "# fill the dataframe with country codes\n",
    "countries_codes = pd.DataFrame({'country': countries_names, 'country_code': countries_codes}, index=None)\n",
    "# merge the 2 dataframes\n",
    "countries = countries.merge(countries_codes, on='country', how='left')\n",
    "countries = countries[['country_code', 'country']]\n",
    "#as a list of tuples\n",
    "countries = [tuple(row) for row in countries.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Country', countries)\n",
    "cursor.execute('SELECT * FROM Country').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'APAC, EMEA, US / Canada', 'AD'),\n",
       " (1, 'Aberdeen, Scotland, United Kingdom', 'DO'),\n",
       " (2, 'Aberdeen, Scotland, United Kingdom - Remote', 'MO'),\n",
       " (3, \"Aix-en-Provence, Provence-Alpes-CÃ´te d'Azur, France\", 'FR'),\n",
       " (4, 'Alberta, Canada - Remote', 'MO'),\n",
       " (5, 'Alexandria, VA', 'VA'),\n",
       " (6, 'All Cities, Spain', 'AI'),\n",
       " (7, 'Amman, Amman Governorate, Jordan', 'JO'),\n",
       " (8, 'Amphoe Si Maha Phot, Thailand', 'AI'),\n",
       " (9, 'Amsterdam', 'AM')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = df[['Location', 'country']].merge(countries_codes, on='country', how='left')\n",
    "# keep only unique locations\n",
    "locations = locations.drop_duplicates(subset=['Location'])\n",
    "# generate an id for each location\n",
    "locations['Location_id'] = locations['Location'].astype('category').cat.codes\n",
    "locations = locations[['Location_id', 'Location', 'country_code']]\n",
    "locations = [tuple(row) for row in locations.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Location', locations)\n",
    "cursor.execute('SELECT * FROM Location').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job_posts\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 810, 798, 'Full_Time', 'Entry-level', 48.0, True, True, 'Data_Science'),\n",
       " (1, 674, 288, 'Full_Time', 'Entry-level', 48.0, True, True, 'Data_Science'),\n",
       " (2, 255, 925, 'Full_Time', 'Not-Specified', 90.0, True, True, 'Artificial_Intelligence'),\n",
       " (3, 159, 627, 'Full_Time', 'Entry-level', 48.0, True, True, 'Data_Science'),\n",
       " (4, 754, 26, 'Full_Time', 'Mid-level', 108.0, True, False, 'Big_Data')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job posts\n",
    "locations_df = df[['Location', 'country']].merge(countries_codes, on='country', how='left')\n",
    "# keep only unique locations_df\n",
    "locations_df = locations_df.drop_duplicates(subset=['Location'])\n",
    "\n",
    "# generate an id for each location\n",
    "locations_df['Location_id'] = locations_df['Location'].astype('category').cat.codes\n",
    "locations_df = locations_df[['Location_id', 'Location', 'country_code']]\n",
    "job_posts = df[['Company', 'Job Title', 'Location', 'Job Type', 'Experience level', 'Salary_in_1000_USD', 'Negociable', 'Asterisk', 'Job_category']].merge(companies_df, on='Company', how='left')\n",
    "job_posts = job_posts.merge(locations_df, on='Location', how='left')\n",
    "job_posts = job_posts[['Company_id', 'Job Title', 'Location_id', 'Job Type', 'Experience level', 'Salary_in_1000_USD', 'Negociable', 'Asterisk', 'Job_category']]\n",
    "\n",
    "# change job categories values to match the enum values\n",
    "job_posts['Job_category'] = job_posts['Job_category'].apply(lambda x: 'Data_Science' if x == 'Data Science' else x)\n",
    "job_posts['Job_category'] = job_posts['Job_category'].apply(lambda x: 'Artificial_Intelligence' if x == 'Artificial Intelligence' else x)\n",
    "job_posts['Job_category'] = job_posts['Job_category'].apply(lambda x: 'Big_Data' if x == 'Big Data' else x)\n",
    "job_posts['Job_category'] = job_posts['Job_category'].apply(lambda x: 'Other' if x == 'Other' else x)\n",
    "\n",
    "# change job types values to match the enum values\n",
    "job_posts['Job Type'] = job_posts['Job Type'].apply(lambda x: 'Full_Time' if x == 'Full Time' else x)\n",
    "job_posts['Job Type'] = job_posts['Job Type'].apply(lambda x: 'Part_Time' if x == 'Part Time' else x)\n",
    "job_posts['Job Type'] = job_posts['Job Type'].apply(lambda x: 'Internship' if x == 'Internship' else x)\n",
    "\n",
    "# change types to str in negociable and asterisk columns\n",
    "job_posts['Negociable'] = job_posts['Negociable'].astype(int)\n",
    "job_posts['Asterisk'] = job_posts['Asterisk'].astype(int)\n",
    "\n",
    "# generate an id for each job post using len\n",
    "job_posts['Id'] = [i for i in range(len(job_posts))]\n",
    "\n",
    "job_posts = job_posts[['Id', 'Company_id', 'Location_id', 'Job Type', 'Experience level', 'Salary_in_1000_USD', 'Negociable', 'Asterisk', 'Job_category']]\n",
    "\n",
    "# replace job_posts['Salary_in_1000_USD'] == 'Negociable' with 0\n",
    "job_posts['Salary_in_1000_USD'] = job_posts['Salary_in_1000_USD'].apply(lambda x: 0 if x == 'Negociable' else x)\n",
    "\n",
    "# as a list of tuples\n",
    "job_posts = [tuple(row) for row in job_posts.values.tolist()]\n",
    "\n",
    "# insert data into the table\n",
    "insert_data('Job_posts', job_posts)\n",
    "\n",
    "cursor.execute('SELECT * FROM Job_posts').fetchmany(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## facilities_of_job\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 21),\n",
       " (1, 21),\n",
       " (2, 2),\n",
       " (3, 21),\n",
       " (4, 33),\n",
       " (4, 12),\n",
       " (4, 23),\n",
       " (4, 11),\n",
       " (5, 11),\n",
       " (5, 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Id'] = [i for i in range(len(df))]\n",
    "# get the unique values of the list\n",
    "facilities = list(set([j for i in df['Facilities'].values for j in i]))\n",
    "# generate an id for each facility\n",
    "facilities_df = pd.DataFrame({'Facility': facilities})\n",
    "facilities_df['Facility_id'] = facilities_df['Facility'].astype('category').cat.codes\n",
    "facilities_df = facilities_df[['Facility_id', 'Facility']]\n",
    "facilities_df = facilities_df[1:]\n",
    "# for each job post get the facilities and the job id\n",
    "facilities_of_the_job = df[['Facilities', 'Id']].explode('Facilities')\n",
    "# drop empty facilities\n",
    "facilities_of_the_job = facilities_of_the_job[facilities_of_the_job['Facilities'] != '']\n",
    "facilities_of_the_job = facilities_of_the_job.merge(facilities_df, left_on='Facilities', right_on='Facility', how='left')\n",
    "facilities_of_the_job = facilities_of_the_job[['Id', 'Facility_id']]\n",
    "facilities_of_the_job = [tuple(row) for row in facilities_of_the_job.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Facilities_of_the_job', facilities_of_the_job)\n",
    "cursor.execute('SELECT * FROM Facilities_of_the_job').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requierements of job\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 136),\n",
       " (0, 63),\n",
       " (0, 88),\n",
       " (0, 267),\n",
       " (0, 252),\n",
       " (0, 193),\n",
       " (1, 16),\n",
       " (1, 123),\n",
       " (1, 86),\n",
       " (1, 262)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique values of the list\n",
    "job_requirements = list(set([j for i in df['Requirment of the company '].values for j in i]))\n",
    "# generate an id for each job requirement\n",
    "job_requirements_df = pd.DataFrame({'Job_requirement': job_requirements})\n",
    "job_requirements_df['Job_requirement_id'] = job_requirements_df['Job_requirement'].astype('category').cat.codes\n",
    "job_requirements_df = job_requirements_df[['Job_requirement_id', 'Job_requirement']]\n",
    "job_requirements_df = job_requirements_df[1:]\n",
    "# for each job post get the job requirements and the job id\n",
    "job_requirements_of_the_job = df[['Requirment of the company ', 'Id']].explode('Requirment of the company ')\n",
    "# drop empty job requirements\n",
    "job_requirements_of_the_job = job_requirements_of_the_job[job_requirements_of_the_job['Requirment of the company '] != '']\n",
    "job_requirements_of_the_job = job_requirements_of_the_job.merge(job_requirements_df, left_on='Requirment of the company ', right_on='Job_requirement', how='left')\n",
    "job_requirements_of_the_job = job_requirements_of_the_job[['Id', 'Job_requirement_id']]\n",
    "job_requirements_of_the_job = [tuple(row) for row in job_requirements_of_the_job.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Requirment_of_the_job', job_requirements_of_the_job)\n",
    "cursor.execute('SELECT * FROM Requirment_of_the_job').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job_Titles\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ' (Permanent Remote)'),\n",
       " (1, ' .NET CORE'),\n",
       " (2, ' 12 months (renewable)'),\n",
       " (3, ' AI'),\n",
       " (4, ' AI & Machine Learning'),\n",
       " (5, ' AI (Remote)'),\n",
       " (6, ' AI / Core Optimization'),\n",
       " (7, ' AI Platform'),\n",
       " (8, ' AI Platform and Solutions'),\n",
       " (9, ' AI Tools')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group Job Title in 1 list then get the unique values\n",
    "df['Job Title'] = df['Job Title'].apply(lambda x: x.split(','))\n",
    "df['Job Title'] = df['Job Title'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# get the unique values of the list\n",
    "job_titles = list(set([j for i in df['Job Title'].values for j in i]))\n",
    "# generate an id for each job title\n",
    "job_titles_df = pd.DataFrame({'Job_title': job_titles})\n",
    "job_titles_df['Job_title_id'] = job_titles_df['Job_title'].astype('category').cat.codes\n",
    "job_titles_df = job_titles_df[['Job_title_id', 'Job_title']]\n",
    "if '' in job_titles_df['Job_title'].values:\n",
    "    job_titles_df = job_titles_df.drop(job_titles_df[job_titles_df['Job_title'] == ''].index)\n",
    "job_titles_df = [tuple(row) for row in job_titles_df.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Job_Titles', job_titles_df)\n",
    "cursor.execute('SELECT * FROM Job_Titles').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job_Title_of_job_posts\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 675),\n",
       " (1, 499),\n",
       " (2, 1429),\n",
       " (3, 532),\n",
       " (4, 950),\n",
       " (5, 2121),\n",
       " (6, 2276),\n",
       " (7, 1328),\n",
       " (8, 2232),\n",
       " (9, 1562)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique values of the list\n",
    "job_titles = list(set(set([j for i in df['Job Title'].values for j in i])))\n",
    "# generate an id for each job title\n",
    "job_titles_df = pd.DataFrame({'Job_title': job_titles})\n",
    "job_titles_df['Job_title_id'] = job_titles_df['Job_title'].astype('category').cat.codes\n",
    "job_titles_df = job_titles_df[['Job_title_id', 'Job_title']]\n",
    "if '' in job_titles_df['Job_title'].values:\n",
    "    job_titles_df = job_titles_df.drop(job_titles_df[job_titles_df['Job_title'] == ''].index)\n",
    "# for each job post get the job titles and the job id\n",
    "job_titles_of_the_job = df[['Job Title', 'Id']].explode('Job Title')\n",
    "# drop empty job titles\n",
    "job_titles_of_the_job = job_titles_of_the_job[job_titles_of_the_job['Job Title'] != '']\n",
    "job_titles_of_the_job = job_titles_of_the_job.merge(job_titles_df, left_on='Job Title', right_on='Job_title', how='left')\n",
    "job_titles_of_the_job = job_titles_of_the_job[['Id', 'Job_title_id']]\n",
    "job_titles_of_the_job = [tuple(row) for row in job_titles_of_the_job.values.tolist()]\n",
    "# insert data into the table\n",
    "insert_data('Job_titles_of_the_job', job_titles_of_the_job)\n",
    "cursor.execute('SELECT * FROM Job_titles_of_the_job').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing connection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
